---
title: 深度学习
date: 2023/2/23
categories:
  - 深度学习
tags:
  - 深度学习
  - pytorch
mathjax: true
abbrlink: 48513
---

## 预备知识

### 名词解释

regression:回归

training data set = training set:训练数据集/训练集

sample = data point = data instance:样本/数据点/数据样本

label = target:标签/目标

feature = covariate:特性/协变量

translation:平移

gradient descent:梯度下降

minibatch stochastic gradient descent:小批量随机梯度下降

batch size:批量大小

hyperparameter tuning:调参



### 矩阵计算

在深度学习相关的资料里面，标量就表示一个数，向量是由多个数组成的。

常规的导数求导没有什么难度，现在将导数扩展到向量，会出现四种情况：

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-03-02_22-49-16.png)

y为标量或向量；x为标量或向量

1、标量求导就不说了，高中常识；
2、y是标量，x是向量的情况。实际上就是y=f(x1,x2,...,xn)的意思。拿y=f(x1,x2)为例解释，有一个三维坐标轴体系，水平面的横轴和竖轴分别是x1、x2，立面上的轴是y，水平面上任意一个点(x1,x2)都对应y轴上的一个点，很明显这就是一个面，**因此他的导数是一个向量**，所以结果是横着写的。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-03-02_22-54-05.png)

3、y是向量，x是标量的情况。这实际上就是【y1,y2,...,yn】=【f(x1),f(x2),...,f(xn)】，对x求导就是求出y=yi时那一个点上的斜率，**结果是标量**，所以结果是竖着写的。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-03-02_22-55-43.png)

4、y、x都是向量的情况。根据上面描述，求导实际上就是求出了y=yi时，那一个平面形状边缘上的**向量**，因此是横着写的。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-03-02_22-56-14.png)

------------------------------------

关于动手学习深度学习，自动微分章节里面2.5.1例子的理解[原链接](https://zh.d2l.ai/chapter_preliminaries/autograd.html)

我们对函数$y=2x^Tx$关于列向量x求导，假设变量x为 $x=[0,1,2,3]$

可以容易的得到y是标量，且值为28.
参考上面提到的四种情况，求导结果应该为向量。

可以把$y=2x^Tx$看作是$y=2x^2$，求导后为$4x$，那么带入$x=[0,1,2,3]$，最后的结果为$[0,4,8,12]$

还有另外一种理解方式，把向量$x$里面的值用${x_1},{x_2}$代替，那么$y=2{x_1^2}+2{x_2^2}+2{x_3^2}+2{x_4^2}$，然后再对每个分量进行求导，即可得到梯度。$[4{x_1},4{x_2},4{x_3},4{x_4}]$，把${x_1},{x_2}$的值带入，得到最终的结果$[0,4,8,12]$

同样的，对于该小节下面的例子
```
x.grad.zero_()  //  x梯度清零，x=[0,1,2,3]
y=x.sum()     // 按上面的方法，y=x1+x2+x3+x4
y.backward()  
x.grad
```
x梯度清零，$x=[0,1,2,3]$

按上面的方法，$y=x1+x2+x3+x4$

$\frac{\partial y}{\partial x} = [1,1,1,1] $


### 损失函数和梯度下降的关系

以线性回归为例，模型为：$y=wx+b$。
其中$w$,$b$是我们要求的参数，深度学习大多数时候就是要把参数求出来

损失函数：为了量化目标的实际值与预测值之间的差距。以平方损失函数为例，带入样本就可以得到差距。损失函数值越小，说明效果越好。**我们就是要找到使损失函数值最小的那组参数**

**梯度下降就是让我们找到那组参数的优化算法**

下面举一个梯度下降法的使用例子。[例子来源](https://www.cnblogs.com/pinard/p/5970503.html)

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/QQ截图20230316215219.png)

上图中步骤4稍微说明下，是单独对每个变量求偏导数后得到的，这样结果就是一个标量而不是向量。具体的过程看下图。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-03-16_21-55-24.png)

**当梯度下降的距离小于给定的值，就停止计算，得到的参数值就是最终的结果。**


### 深度学习为什么要加入隐藏层

**让特征可以更好的进行线性划分**

[原链接](https://zhuanlan.zhihu.com/p/114925231)

例如区分以下三张图片哪个是人脸，也就是人脸识别，神经网络模型应该怎么建立呢？为了简单起见，输入层的每个节点代表图片的某个像素，个数为像素点的个数，输出层简单地定义为一个节点，标示是还是不是。

那么隐含层怎么分析呢？ 我们先从感性地角度认识这个人脸识别问题，试着将这个问题分解为一些列的子问题，比如，

在上方有头发吗？

在左上、右上各有一个眼睛吗？

在中间有鼻子吗？

在下方中间位置有嘴巴吗？

在左、右两侧有耳朵吗？

假如对以上这些问题的回答，都是“yes”，或者大部分都是“yes”，那么可以判定是人脸，否则不是人脸。但是，这种判断忽略了某些特殊情况，比如某个人没有长头发，某个人的左半边脸被花丛遮挡了等等，等处在这些环境中时，这种方法的判断可能会有问题。

承上，将原问题分解为子问题的过程如果用神经网络来表达的话，可以这样表示，方框表示为某个子网络：

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/v2-ede0b2e88c349591fa6e47c4d3a96b8e_720w.webp)

以上每个子网络，还可以进一步分解为更小的问题，比如判断左上是一个眼睛吗的问题，可以分解为：

有眼球吗？
有眼睫毛吗？
有虹膜吗？
…

以上，这个子网络还可以进一步分解，.一层又一层地分解，直到，回答的问题简单到能在一个单独的神经元上被回答。

这种带有两个或多个隐含层的神经网络，称为深度神经网络，deep neural networks，简称为 DNN。

### 熵、信息熵、相对熵、KL散度、交叉熵损失、softmax

#### softmax

softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持 可导的性质



#### 熵和信息熵

熵和信息熵本质是一个东西，就是换了个说法而已。

熵：在信息论中则表示事务的不确定性。信息量与信息熵是相对的，告诉你一件事实，你获取了信息量，但减少了熵。或者说，得知一件事实后信息熵减少的量，就是你得到的这个事实所包含的信息的量。

熵的公式：$H(x)=-\sum_{i=1}^{n} P\left(x_{i}\right) \log _{2} P\left(x_{i}\right)$

n:表示随机变量可能的取值
x:表示随机变量
P(x):表示随机变量x的概率函数

**log以10，2或者e为底，对结果熵的判断没有影响**

#### 相对熵和交叉熵
**相对熵就是KL散度**

$D_{K L}(p \| q)=\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(\frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}\right)$

用于衡量两个概率分布之间的差异。

我们把上面的公式展开

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-04-07_10-59-34.png)


$$\begin{aligned} 
D_{K L}(p \| q)&=\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(\frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}\right) \\
               &=\sum_{i=1}^{n}p(x_{i})l o g\,p(x_{i})-\sum_{i=1}^{n}p(x_{i})l o g q(x_{i})\\
               &= -(-\sum_{i=1}^{n}p(x_{i})l o g\,p(x_{i})) - \sum_{i=1}^{n}p(x_{i})l o g q(x_{i})                     \\
               &=  -H(P) + H(P,Q)               \\
               &= H(P,Q) -H(P)              \\
               &= 交叉熵 - 信息熵                      \\
\end{aligned}$$ 

p(x)表示真实概率分布，q(x)表示预测概率分布
**交叉熵刻画的是实际输出（概率）与期望输出（概率）的距离，也就是交叉熵的值越小，两个概率分布就越接近，即拟合的更好。**

当p(x)=q(x)时，相对熵为0
相对熵越小越好，相对熵和交叉熵的差距只有一个常数。那么相对熵达到最小值的适合，也就是交叉熵达到最小的时候。所以对q(x)的优化等效于求交叉熵的最小值，交叉熵的最小值也就是求最大似然估计

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/v2-95c59c2a55a6782d45b20b9e00913da7_1440w.webp)


#### 似然函数、极大似然函数

p(x|θ)也是一个有着两个变量的函数。如果，你将θ设为常量，则你会得到一个概率函数（关于x的函数）；如果，你将x设为常量你将得到似然函数（关于θ的函数）。

概率描述的是：指定参数后，预测即将发生事件的可能性；

似然描述的是：在已知某些观测所得到的结果时，对有关事物的性质的参数进行估计；

极大似然估计是在已知一堆数据和分布类型的前提下，反推最有可能的参数是什么，也就是“它最像这个分布哪组参数下表现出来的数据”。

举个例子：

将抽球结果作为$X$，即离散随机变量，设白球为 
$X=1$，黑球为 $X=0$。假设抽到白球的概率为 $\theta$，$\theta$ 即是未知的需要通过极大似然估计得出的参数。

写出一次预测的似然函数：
$$L(\theta|x)=f(x|\theta)=P(x,\theta)=\theta^{x}*{(1-\theta)}^{(1-x)}$$

这里解释下为什么是这样的：

如果抽到的是白球，就是$X=1$,密度函数是$\theta$，带入公式没有问题；
如果抽到的是黑球，就是$X=0$,密度函数是$1-\theta$，带入公式没有问题；

对于二项分布，出现符合观测情况的，白球出现7次，黑球出现三次的概率密度函数为
$P(X,\theta)=P(x1,\theta)*P(x2,\theta)*..\cdot P(x10,\theta)=\theta^{7}*(1-\theta)^{3}$

写成似然函数形式为：

$L(\theta|X)=P(X,\theta)=\theta^{7}*(1-\theta)^{3}$

#### 似然函数和交叉熵的关系

为了求最大的似然函数，我们往往取对数，最后发现二分类的极大似然函数和二分类交叉熵相同

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/Snipaste_2023-04-07_21-07-24.png)

[原文链接](https://blog.51cto.com/u_15899958/5909794)

### 欠拟合、过拟合
[原文链接](https://zhuanlan.zhihu.com/p/72038532)


训练误差：模型在训练数据集上计算得到的误差

泛化误差：模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。

度量泛化能力的好坏，最直观的表现就是模型的过拟合（overfitting）和欠拟合（underfitting）。过拟合和欠拟合是用于描述模型在训练过程中的两种状态。一般来说，训练过程会是如下所示的一个曲线图。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/v2-0ecc4dee7383ccf1995de08cdddc84d9_720w.jpg)

训练刚开始的时候，模型还在学习过程中，处于欠拟合区域。随着训练的进行，训练误差和测试误差都下降。在到达一个临界点之后，训练集的误差下降，测试集的误差上升了，这个时候就进入了过拟合区域——由于训练出来的网络过度拟合了训练集，对训练集以外的数据却不work。

1. 什么是欠拟合

欠拟合是指模型不能在训练集上获得足够低的误差。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。

2. 如何解决欠拟合
欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过增加网络复杂度或者在模型中增加特征，这些都是很好解决欠拟合的方法。

3. 什么是过拟合

过拟合是指训练误差和测试误差之间的差距太大。换句换说，就是模型复杂度高于实际问题，模型在训练集上表现很好，但在测试集上却表现很差。模型对训练集"死记硬背"（记住了不适用于测试集的训练集性质或特点），没有理解数据背后的规律，泛化能力差。

4. 为什么会出现过拟合

造成原因主要有以下几种：
1、训练数据集样本单一，样本不足。如果训练样本只有负样本，然后那生成的模型去预测正样本，这肯定预测不准。所以训练样本要尽可能的全面，覆盖所有的数据类型。
2、训练数据中噪声干扰过大。噪声指训练数据中的干扰数据。过多的干扰会导致记录了很多噪声特征，忽略了真实输入和输出之间的关系。
3、模型过于复杂。模型太复杂，已经能够“死记硬背”记下了训练数据的信息，但是遇到没有见过的数据的时候不能够变通，泛化能力太差。我们希望模型对不同的模型都有稳定的输出。模型太复杂是过拟合的重要因素。

5. 如何防止过拟合

要想解决过拟合问题，就要显著减少测试误差而不过度增加训练误差，从而提高模型的泛化能力。我们可以使用正则化（Regularization）方法。那什么是正则化呢？正则化是指修改学习算法，使其降低泛化误差而非训练误差。

常用的正则化方法根据具体的使用策略不同可分为：（1）直接提供正则化约束的参数正则化方法，如L1/L2正则化；（2）通过工程上的技巧来实现更低泛化误差的方法，如提前终止(Early stopping)和Dropout；（3）不直接提供约束的隐式正则化方法，如数据增强等。

## 度量学习

### 概念

度量学习 (Metric Learning) == 距离度量学习 (Distance Metric Learning，DML) == 相似度学习。

在数学中,一个度量(或距离函数)是一个定义集合中元素之间"距离"的函数.

一个具有度量的集合可以称之为度量空间.

**“不同于分类学习，度量学习是通过学习数据之间的相似性程度来获得一个更有意义或者说更具可分性的特征空间。”**

### 度量学习作用
比较样本点和中心点的相似度.



### 为什么要用度量学习/度量学习和传统分类方法的区别

K-means、K近邻方法、SVM等算法，比较依赖于输入时给定的度量，比如：数据之间的相似性，那么将面临的一个基本的问题是如何获取数据之间的相似度。为了处理各种各样的特征相似度，我们可以在特定的任务通过选择合适的特征并手动构建距离函数。然而这种方法会需要很大的人工投入，也可能对数据的改变非常不鲁棒。度量学习作为一个理想的替代，可以根据不同的任务来自主学习出针对某个特定任务的度量距离函数。


### 深度度量学习和传统度量学习的区别

对于传统度量学习而言，由于其处理原始数据的能力有限，因此需要首先使用特征工程的知识对数据进行预处理，然后再用度量学习的算法进行学习。一些传统的度量学习方法只能学习出线性特征，虽然有一些能够提取非线性特征的核方法被提出，但对学习效果也没有明显提升。随着深度学习的出现，得益于激活函数学习非线性特征的优秀能力，深度学习方法能够自动地从原始数据中学出高质量的特征。因此深度学习的网络结构与传统的度量学习方法相结合能够带来理想的效果。如图2所示，采用MNIST作为例子，a中的橙色线条是同类样本之间的距离，蓝色线条是异类样本之间的距离。b是随着训练的进行，这两种距离的变化趋势。可以看出同类样本间距离减小，异类样本间距离增加。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/v2-ff8034cbf2b2e8b8740bd1e92202febb_720w.webp)

### 深度度量学习

通过深层结构，学习到高抽象化的非线性特征以及数据之间的相似性关系。

DML三大关键点： **采样策略、合适的距离度量函数以及模型结构**，因此当前DML模型往往基于指定任务在这些方面进行改进。

[原文链接](https://blog.csdn.net/supergxt/article/details/118155049)

### 度量学习类别
从广义上可以将度量学习分为:(1)通过线性变换的度量学习和非线性模型的度量学习.

（1）线性变换的度量学习

线性度量学习问题也称为马氏度量学习问题,又可以分为监督学习和非监督学习两类.

监督的全局度量学习：
Information-theoretic metric learning(ITML)
Mahalanobis Metric Learning for Clustering(MMC)
Maximally Collapsing Metric Learning (MCML)

监督的局部度量学习：
Neighbourhood Components Analysis (NCA)
Large-Margin Nearest Neighbors (LMNN)
Relevant Component Analysis(RCA)
Local Linear Discriminative Analysis(Local LDA)

非监督的度量学习：
主成分分析(Pricipal Components Analysis, PCA)
多维尺度变换(Multi-dimensional Scaling, MDS)
非负矩阵分解(Non-negative Matrix Factorization,NMF)
独立成分分析(Independent components analysis, ICA)
邻域保持嵌入(Neighborhood Preserving Embedding,NPE)
局部保留投影(Locality Preserving Projections. LPP)

（2）非线性模型
非线性降维算法可以看作属于非线性度量学习：
等距映射(Isometric Mapping,ISOMAP)
局部线性嵌入(Locally Linear Embedding, LLE) 
拉普拉斯特征映射(Laplacian Eigenmap，LE ) 

通过核方法来对线性映射进行扩展：
Non-Mahalanobis Local Distance Functions
Mahalanobis Local Distance Functions
Metric Learning with Neural Networks

## 卷积神经网络

### 传统神经网络
[原文链接](https://www.ruanyifeng.com/blog/2017/07/neural-network.html)

神经网络搭建需要满足三个条件：
1. 输入和输出
2. 权重（w）和阈值（b）
3. 多层感知器的结构

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/bg2017071205.png)

其中，最困难的部分就是确定权重（w）和阈值（b）。目前为止，这两个值都是主观给出的，但现实中很难估计它们的值，必需有一种方法，可以找出答案。

这种方法就是试错法。其他参数都不变，w（或b）的微小变动，记作Δw（或Δb），然后观察输出有什么变化。不断重复这个过程，直至得到对应最精确输出的那组w和b，就是我们要的值。这个过程称为模型的训练。

因此，神经网络的运作过程如下：
1. 确定输入和输出
2. 找到一种或多种算法（数学公式），可以从输入得到输出
3. 找到一组已知答案的数据集，用来训练模型，估算w和b
4. 一旦新的数据产生，输入模型，就可以得到结果，同时对w和b进行校正

### 传统神经网络的问题
1. 图像需要处理的数据量太大，导致成本很高，效率很低

现在随随便便一张图片都是 1000×1000 像素以上的， 每个像素都有RGB 3个参数来表示颜色信息。

假如我们处理一张 1000×1000 像素的图片，我们就需要处理3百万个参数！

1000×1000×3=3,000,000

**卷积神经网络 – CNN 解决的第一个问题就是「将复杂问题简化」，把大量参数降维成少量参数，再做处理。**

2. 图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高
![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/98412-2019-06-12-tuxiangtx.png.webp)

假如有圆形是1，没有圆形是0，那么圆形的位置不同就会产生完全不同的数据表达。但是从视觉的角度来看，图像的内容（本质）并没有发生变化，只是位置发生了变化。

所以当我们移动图像中的物体，用传统的方式的得出来的参数会差异很大！这是不符合图像处理的要求的。

**CNN 解决了这个问题，他用类似视觉的方式保留了图像的特征，当图像做翻转，旋转或者变换位置时，它也能有效的识别出来是类似的图像。**

### CNN的基本步骤
卷积神经网络（Convolutional Neural Network，CNN）是一种在计算机视觉和图像处理任务中广泛应用的深度学习模型。CNN通过模拟生物视觉系统中神经元的工作原理，能够自动学习图像和视频等数据的特征表示。

CNN的基本概念包括以下几个要素：

1. 卷积层（Convolutional Layer）：卷积层是CNN的核心组成部分。它通过使用一系列可学习的滤波器（也称为卷积核）对输入图像进行卷积操作，从而提取图像中的局部特征。卷积层的输出被称为特征图（Feature Map）。

2. 池化层（Pooling Layer）：池化层用于减少特征图的空间维度，同时保留主要的特征信息。常用的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。池化层可以帮助减少计算量，提取图像的不变性，并且能够控制模型的过拟合。

3. 激活函数（Activation Function）：激活函数引入非线性性质，使得CNN能够学习复杂的非线性特征。常用的激活函数包括ReLU（Rectified Linear Unit）、Sigmoid和Tanh等。

4. 全连接层（Fully Connected Layer）：全连接层将前面的卷积层和池化层的输出连接到输出层，进行最终的分类或回归任务。

5. 反向传播（Backpropagation）：CNN利用反向传播算法进行训练。反向传播通过计算损失函数关于模型参数的梯度，以更新模型参数来最小化损失函数。

下面是一个简单的CNN示例，以图像分类为任务：

输入：一张32x32像素的彩色图像
1. 卷积层：使用一组3x3大小的卷积核，对输入图像进行卷积操作，得到特征图。
2. 激活函数：对特征图的每个元素应用ReLU激活函数，增加非线性性质。
3. 池化层：使用2x2大小的最大池化，将特征图的尺寸减半。
4. 卷积层：再次使用一组3x3大小的卷积核，对池化后的特征图进行卷积操作，得到新的特征图。
5. 激活函数：对新的特征图的每个元素应用ReLU激活函数。
6. 池化层：再次使用2x2大小的最

大池化，将特征图的尺寸减半。
7. 展平层（Flatten）：将池化层的输出展平为一维向量。
8. 全连接层：将展平的向量连接到全连接层，并应用激活函数。
9. 输出层：使用适当的激活函数（如Softmax）进行多类别分类。

这个例子只是一个简化的CNN结构，实际中可能会有更多的卷积层、池化层和全连接层，以及一些正则化和优化技巧，来提高模型的性能和稳定性。

请注意，具体的CNN结构和参数设置会根据不同的任务和数据集而有所不同，需要根据实际情况进行调整和优化。

### 如何理解多尺度CNN中的尺度
在多尺度CNN中，"多尺度"指的是对输入数据进行不同尺度的处理和分析。这种处理方式可以帮助网络更好地捕捉到输入数据中的多尺度特征，从而提高模型的性能和泛化能力。

通常，多尺度CNN会通过以下几种方式来实现多尺度处理：

1. 多尺度输入：将输入数据在不同尺度下进行变换，例如通过缩放、裁剪或填充等操作，以获取不同尺度的图像输入。这样，网络可以同时关注不同尺度下的特征信息。

2. 多尺度卷积：在网络的某些层中使用不同大小的卷积核或不同步长的卷积操作，以捕捉不同尺度的特征。这样，网络可以通过不同尺度的卷积感受野来分析输入数据。

3. 多尺度池化：在池化层中使用不同大小的池化窗口或不同步长的池化操作，以对特征图进行降采样。这样可以保留不同尺度下的特征信息。

4. 多尺度特征融合：将来自不同尺度的特征进行融合，以综合利用不同尺度的信息。这可以通过特征图的级联、加权求和、并行分支等方式来实现。

通过多尺度处理，多尺度CNN能够更好地适应不同尺度的目标或特征，并更全面地理解输入数据。这对于许多计算机视觉任务如目标检测、语义分割和图像分类等是非常有益的。

### 什么是CNN的尺度(scale)

[原文链接](https://blog.csdn.net/xjp_xujiping/article/details/110324506)

[相关链接](https://blog.csdn.net/m0_47891203/article/details/124202487)

卷积神经网络里涉及到三种尺度：深度、宽度、分辨率。
- 深度指的是网络有多深，或者说有多少层。
- 宽度指的是网络有多宽，比如卷积层的通道数。
- 分辨率指的是输入卷积层的图像、特征图的空间分辨率。

也可以简单的理解为不同尺寸的图片，或者不同分辨率的图片。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/7df63c0c5b279fc8251f0075c04f2a9f.png)

模型尺度。(a) 是一个基本的网络模型；(b)-(d) 分别单独在宽度、深度、分辨率的维度上增加尺度；(e) 是论文提出的混合尺度变换，用统一固定的比例放缩三个不同维度的尺度。

### 感受野
若感受野太小，表明网络只能观察到图像的局部特征；若感受野太大，虽然对全局信息理解更强，但通常也包含了许多无效信息。为了提高有效感受野从而避免冗余信息，捕获多尺度特征是当前研究者们常采用的方法。比如拿望远镜看远方为小视野，直接光看为大视野。

## 算法介绍

### KNN算法
[原链接](https://zhuanlan.zhihu.com/p/25994179)

#### 基本概念

K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例，这K个实例的多数属于某个类，就把该输入实例分类到这个类中。（这就类似于现实生活中少数服从多数的思想）根据这个说法，咱们来看下引自维基百科上的一幅图：

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/v2-c3f1d2553e7467d7da5f9cd538d2b49a_720w.png)

如上图所示，有两类不同的样本数据，分别用蓝色的小正方形和红色的小三角形表示，而图正中间的那个绿色的圆所标示的数据则是待分类的数据。这也就是我们的目的，来了一个新的数据点，我要得到它的类别是什么？好的，下面我们根据k近邻的思想来给绿色圆点进行分类。

如果K=3，绿色圆点的最邻近的3个点是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。

如果K=5，绿色圆点的最邻近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于蓝色的正方形一类。

从上面例子我们可以看出，k近邻的算法思想非常的简单，也非常的容易理解，那么我们是不是就到此结束了，该算法的原理我们也已经懂了，也知道怎么给新来的点如何进行归类，只要找到离它最近的k个实例，哪个类别最多即可。

#### k近邻算法中k的选取以及特征归一化的重要性

1. 选取k值以及它的影响

如果我们选取较小的k值，那么就会意味着我们的整体模型会变得复杂，容易发生过拟合

如果我们选取较大的k值，就相当于用较大邻域中的训练数据进行预测，这时与输入实例较远的（不相似）训练实例也会对预测起作用，使预测发生错误，k值的增大意味着整体模型变得简单。我们很容易学习到噪声。



我们想，如果k=N（N为训练样本的个数）,那么无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类。这时，模型是不是非常简单，这相当于你压根就没有训练模型呀！

2. 距离的度量
在上文中说到，k近邻算法是在训练数据集中找到与该实例最邻近的K个实例，这K个实例的多数属于某个类，我们就说预测点属于哪个类。

定义中所说的最邻近是如何度量呢？我们怎么知道谁跟测试点最邻近。这里就会引出我们几种度量俩个点之间距离的标准。

**度量学习可以应用于此**


3. 特征归一化的必要性
为了保证每个特征同等重要性，我们这里对每个特征进行归一化。

## 线性神经网络
### 线性回归

线性回归基于几个简单的假设： 首先，假设自变量$x$
和因变量$y$之间的关系是线性的， 即$y$可以表示为$x$
中元素的加权和，这里通常允许包含观测值的一些噪声； 其次，我们假设任何噪声都比较正常，如噪声遵循正态分布。

<!-- 线性模型：$\hat{y}=w_1x_1+...+w_dx_d+b$ -->

**线性回归的关键在于寻找最好的模型参数**，需要两个东西：
（1）一种模型质量的度量方式：**损失函数**
（2）一种能够更新模型以提高模型预测质量的方法：**优化算法**

模型的优化过程就是：随机抽样一个小批量$\beta$，它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数$\eta$，并从当前参数的值中减掉。

## conda常用命令

1. 获取版本号
```
conda --version
// conda -V
```
2. 获取帮助
```
conda --help
conda -h
```
查看某一命令的帮助，如update命令及remove命令
```
conda update --help
conda remove --help
```

3. 创建环境
```
conda create --name your_env_name
```

创建制定python版本的环境

```
conda create --name your_env_name python=2.7
conda create --name your_env_name python=3
conda create --name your_env_name python=3.5
```

列举当前所有环境

```
conda info --envs
conda env list
```
进入某个环境

```
activate your_env_name
```
退出当前环境

```
deactivate 
```

复制某个环境
```
conda create --name new_env_name --clone old_env_name 
```
删除某个环境

```
conda remove --name your_env_name --all
```


## pytorch安装

### cuda安装
[原链接](https://zhuanlan.zhihu.com/p/94220564)

桌面右键打开英伟达控制面板，点击帮助->系统信息->组件

可以看到支持的版本，安装的cuda版本必须小于等于该版本

安装好cuda后，安装cuDNN。
版本要和cuda对应起来

### miniconda和pytorch安装

[原链接](https://zhuanlan.zhihu.com/p/174738684)


[miniconda的镜像](https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/)

要注意安装的是x86_64的版本，一开始装成的x86(32位，一直出问题)

安装pytorch的时候要进入[这里](https://pytorch.org/get-started/previous-versions/)。根据对应的cuda版本来下载，最然根据教程来验证是否安装成果。



### 安装jupyter notebook

安装jupyter notebook有三个办法：

**方法1：**
**为每一个 conda 环境 都安装 jupyter**

上面的安装好以后，使用```conda activate d2l```，激活d2l环境。
用```conda install jupyter```安装一直卡在那，换pip安装。但是还是因为网速原因没成功，可以使用临时换源的办法：

```pip install jupyter -i https://pypi.tuna.tsinghua.edu.cn/simple```



**方法2：**

在base环境安装好jupyter后

```
conda create -n my-conda-env                               # creates new virtual env
conda activate my-conda-env                                # activate environment in terminal
conda install ipykernel                                    # install Python kernel in new conda env
ipython kernel install --user --name=my-conda-env-kernel   # configure Jupyter to use Python kernel
```

然后在base环境运行jupyter，下面两种方式都可以切换环境

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/微信图片_20230315114520.png)

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/微信图片_20230315114528.png  )

**缺点是你新建一个环境，就要重复操作一次**

**方法3：**

```
conda activate my-conda-env    # this is the environment for your project and code
conda install ipykernel
conda deactivate

conda activate base      # could be also some other environment
conda install nb_conda_kernels
jupyter notebook
```

注意：这里的 ```conda install nb_conda_kernels``` 是在 base 环境下操作的。

然后就可以进行conda环境求换，方式和法2相同。

本人在使用方法3的时候遇到了问题，web端显示500，命令行显示的关键信息如下：

**ImportError: cannot import name 'contextfilter' from 'jinja2'**

最后的解决方法：
```
conda update nbconvert
```

### 导入torchvision出现错误

cuda和pythorch都安装成功的时候，且gpu也能正常使用。但是运行d2l里面的代码报错：
```
import torch 成功

import torchvision,报错

DLL:找不到模块
```

根据torch版本找到对应的torchvision，然后卸载torchvision再安装，显示没有这个版本。当时安装torch的时候，torchvision也安装了，且版本正确。

**解决办法：**
1. 先查看一下Pillow的版本
  
```
pip show Pillow
```

如果没有直接安装
```
pip install Pillow
```

如果有，先卸载
```
pip uninstall Pillow
```

再安装
```
pip install Pillow
```

然后检验torchvision是否正常
```
>>> import torchvision
>>> torchvision.__version__
'0.8.2'

```


