---
title: CNN
date: 2026/01/22
categories:
  - AI
tags:
  - CNN
mathjax: true
---


## 卷积神经网络（CNN）

### 传统神经网络
[原文链接](https://www.ruanyifeng.com/blog/2017/07/neural-network.html)


神经网络搭建需要满足三个条件：
1. 输入和输出
2. 权重（w）和阈值（b）
3. 多层感知器的结构

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/bg2017071205.png)

其中，最困难的部分就是确定权重（w）和阈值（b）。目前为止，这两个值都是主观给出的，但现实中很难估计它们的值，必需有一种方法，可以找出答案。

这种方法就是试错法。其他参数都不变，w（或b）的微小变动，记作Δw（或Δb），然后观察输出有什么变化。不断重复这个过程，直至得到对应最精确输出的那组w和b，就是我们要的值。这个过程称为模型的训练。

因此，神经网络的运作过程如下：
1. 确定输入和输出
2. 找到一种或多种算法（数学公式），可以从输入得到输出
3. 找到一组已知答案的数据集，用来训练模型，估算w和b
4. 一旦新的数据产生，输入模型，就可以得到结果，同时对w和b进行校正

### 传统神经网络数学公式推导（全连接）
[原文链接](https://zhuanlan.zhihu.com/p/273595649)




### 传统神经网络的问题
1. 图像需要处理的数据量太大，导致成本很高，效率很低

现在随随便便一张图片都是 1000×1000 像素以上的， 每个像素都有RGB 3个参数来表示颜色信息。

假如我们处理一张 1000×1000 像素的图片，我们就需要处理3百万个参数！

1000×1000×3=3,000,000

**卷积神经网络 – CNN 解决的第一个问题就是「将复杂问题简化」，把大量参数降维成少量参数，再做处理。**

2. 图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高
![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/98412-2019-06-12-tuxiangtx.png.webp)

假如有圆形是1，没有圆形是0，那么圆形的位置不同就会产生完全不同的数据表达。但是从视觉的角度来看，图像的内容（本质）并没有发生变化，只是位置发生了变化。

所以当我们移动图像中的物体，用传统的方式的得出来的参数会差异很大！这是不符合图像处理的要求的。

**CNN 解决了这个问题，他用类似视觉的方式保留了图像的特征，当图像做翻转，旋转或者变换位置时，它也能有效的识别出来是类似的图像。**

具体表现为：

**CNN（卷积神经网络）相对于传统的全连接神经网络（FNN），可以通过卷积层（权值共享、局部连接）和池化层（空间维度的降采样）的设计来实现参数降维，从而减少模型中的参数数量。**

### CNN的基本步骤
卷积神经网络（Convolutional Neural Network，CNN）是一种在计算机视觉和图像处理任务中广泛应用的深度学习模型。CNN通过模拟生物视觉系统中神经元的工作原理，能够自动学习图像和视频等数据的特征表示。

CNN的基本概念包括以下几个要素：
[相关链接，写的不错](https://blog.csdn.net/v_JULY_v/article/details/51812459)

1. 卷积层（Convolutional Layer）：卷积层是CNN的核心组成部分。它通过使用一系列可学习的滤波器（也称为卷积核）对输入图像进行卷积操作，从而提取图像中的局部特征。卷积层的输出被称为特征图（Feature Map）。

2. 池化层（Pooling Layer）：池化层用于减少特征图的空间维度，同时保留主要的特征信息。池化层也称为下采样。常用的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。池化层可以帮助减少计算量，提取图像的不变性，并且能够控制模型的过拟合。

3. 激活函数（Activation Function）：激活函数引入非线性性质，使得CNN能够学习复杂的非线性特征。常用的激活函数包括ReLU（Rectified Linear Unit）、Sigmoid和Tanh等。

4. 全连接层（Fully Connected Layer）：全连接层将前面的卷积层和池化层的输出连接到输出层，进行最终的分类或回归任务。

5. 反向传播（Backpropagation）：CNN利用反向传播算法进行训练。反向传播通过计算损失函数关于模型参数的梯度，以更新模型参数来最小化损失函数。

下面是一个简单的CNN示例，以图像分类为任务：

输入：一张32x32像素的彩色图像
1. 卷积层：使用一组3x3大小的卷积核，对输入图像进行卷积操作，得到特征图。
2. 激活函数：对特征图的每个元素应用ReLU激活函数，增加非线性性质。
3. 池化层：使用2x2大小的最大池化，将特征图的尺寸减半。
4. 卷积层：再次使用一组3x3大小的卷积核，对池化后的特征图进行卷积操作，得到新的特征图。
5. 激活函数：对新的特征图的每个元素应用ReLU激活函数。
6. 池化层：再次使用2x2大小的最

大池化，将特征图的尺寸减半。
7. 展平层（Flatten）：将池化层的输出展平为一维向量。
8. 全连接层：将展平的向量连接到全连接层，并应用激活函数。
9. 输出层：使用适当的激活函数（如Softmax）进行多类别分类。

这个例子只是一个简化的CNN结构，实际中可能会有更多的卷积层、池化层和全连接层，以及一些正则化和优化技巧，来提高模型的性能和稳定性。

请注意，具体的CNN结构和参数设置会根据不同的任务和数据集而有所不同，需要根据实际情况进行调整和优化。

### CNN数学公式推导
[链接1](https://blog.csdn.net/weipf8/article/details/103917202)

[链接2](https://tech.youmi.net/2016/07/163347168.html)


二维卷积公式：
```
torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
```


输出图像的高、宽计算公式:
![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/Snipaste_2024-01-10_10-44-21.png)




卷积的过程：

<!-- <img src="gif/convProcess.gif" width = "" height = ""> -->

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/convProcess.gif)

卷积神经网络是权值共享，非全连接的神经网络。以2个卷积层和2个池化层的卷积神经网络为例，其结构图如下：

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/a7b9429e-436f-11e6-85c5-ceab16a79342.jpg)

从这个图可以看出几个关键的地方：
1. 卷积层和池化（采样）层结束的时候都需要一个激活函数，就是f(.)。
2. 卷积核可以不止有一个，可以采用多个卷积核分别进行卷积, 这样便可以得到多个特征图。有时, 对于一张三通道彩色图片, 或者如第三层特征图所示, 输入的是一组矩阵, 这时卷积核也不再是一层的, 而要变成相应的深度.

<!-- <img src="gif/Three-channelFeature.gif" width = "" height = ""> -->

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/Three-channelFeature.gif)

上图中是经过一次卷积后的结果，得到了3个特征图。再次卷积时，输入的是一组矩阵, 这时卷积核也不再是一层的, 而要变成相应的深度。, 最左边是输入的特征图矩阵, 深度为 3, 补零(Zero Padding)层数为 1, 每次滑动的步幅为 2. 中间两列粉色的矩阵分别是两组卷积核, 一组有三个, 三个矩阵分别对应着卷积左侧三个输入矩阵, 每一次滑动卷积会得到三个数, 这三个数的和作为卷积的输出. 最右侧两个绿色的矩阵分别是两组卷积核得到的特征图。

### 如何理解多尺度CNN中的尺度
在多尺度CNN中，"多尺度"指的是对输入数据进行不同尺度的处理和分析。这种处理方式可以帮助网络更好地捕捉到输入数据中的多尺度特征，从而提高模型的性能和泛化能力。

通常，多尺度CNN会通过以下几种方式来实现多尺度处理：

1. 多尺度输入：将输入数据在不同尺度下进行变换，例如通过缩放、裁剪或填充等操作，以获取不同尺度的图像输入。这样，网络可以同时关注不同尺度下的特征信息。

2. 多尺度卷积：在网络的某些层中使用不同大小的卷积核或不同步长的卷积操作，以捕捉不同尺度的特征。这样，网络可以通过不同尺度的卷积感受野来分析输入数据。

3. 多尺度池化：在池化层中使用不同大小的池化窗口或不同步长的池化操作，以对特征图进行降采样。这样可以保留不同尺度下的特征信息。

4. 多尺度特征融合：将来自不同尺度的特征进行融合，以综合利用不同尺度的信息。这可以通过特征图的级联、加权求和、并行分支等方式来实现。

通过多尺度处理，多尺度CNN能够更好地适应不同尺度的目标或特征，并更全面地理解输入数据。这对于许多计算机视觉任务如目标检测、语义分割和图像分类等是非常有益的。

### 什么是CNN的尺度(scale)

[原文链接](https://blog.csdn.net/xjp_xujiping/article/details/110324506)

[相关链接](https://blog.csdn.net/m0_47891203/article/details/124202487)

卷积神经网络里涉及到三种尺度：深度、宽度、分辨率。
- 深度指的是网络有多深，或者说有多少层。
- 宽度指的是网络有多宽，比如卷积层的通道数。
- 分辨率指的是输入卷积层的图像、特征图的空间分辨率。

也可以简单的理解为不同尺寸的图片，或者不同分辨率的图片。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img/7df63c0c5b279fc8251f0075c04f2a9f.png)

模型尺度。(a) 是一个基本的网络模型；(b)-(d) 分别单独在宽度、深度、分辨率的维度上增加尺度；(e) 是论文提出的混合尺度变换，用统一固定的比例放缩三个不同维度的尺度。

### 感受野
若感受野太小，表明网络只能观察到图像的局部特征；若感受野太大，虽然对全局信息理解更强，但通常也包含了许多无效信息。为了提高有效感受野从而避免冗余信息，捕获多尺度特征是当前研究者们常采用的方法。比如拿望远镜看远方为小视野，直接光看为大视野。




