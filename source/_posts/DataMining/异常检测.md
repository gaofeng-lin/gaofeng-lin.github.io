---
title: 异常检测
date: 2025/03/07
categories:
  - DataMining
tags:
  - 异常检测
mathjax: true
abbrlink: 2ede883b
---



## 无监督训练流程

无监督训练和有监督训练的区别在于没有标签，数据不需要提前标注。之所以采用无监督训练，是因为异常检测领域中异常数据往往是很少的。如果采用有监督训练，那么会优先学习正常数据的分布，就无法识别异常。

采用无监督训练，一种常见的策略是重建。我们这里以设备监控为例，一台设备在100个连续时刻采集了5个传感器的数据，这样的数据为一个样本。一共采集10个这样的数据。输入维度为（10，100，5）

模型的输出是重构后的时序数据，与原始的数据比较后，计算Loss，反向传播更新参数。设定阈值，假设超过阈值的就是异常，就判定哪个时刻，哪个传感器的值是异常的。


## 评价指标

混淆矩阵是分类任务中评价指标很重要的概念。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/v2-4e0f7a071cd42e3a19e5fc594e35443b_1440w.jpg)

Positive/Negative 表示的预测结果，前面的True/False表示预测的结果是否为真。

- True Positive(真正, TP)：预测正样本正确 
- True Negative(真负 , TN)：预测负样本正确
- False Positive(假正, FP)：预测正样本错误
- False Negative(假负 , FN)：预测负样本错误

### 准确率

预测正确的结果占所有样本的比例

Accuracy = (TP + TN) / (TP + TN + FP +FN)

### 精确率

预测Positive的成功率占多少

Precision = TP / (TP + FP)

衡量模型的预测可靠性。准确率高意味着模型“宁可漏检，也不错检”。

### 召回率

所有正样本中，被正确预测占多少

Recall = TP / (TP + FN)

衡量模型的覆盖能力。召回率高意味着模型“宁可错检，也不漏检”。



## 为什么在异常样本较少的时候，我们大多采用无监督而非有监督训练

有监督训练：学习异常与正常的决策边界，将数据分为两类；数学本质是条件概率；代表性方法有SVM、神经网络分类器

这种情况下，**模型有可能把所有样本都预测为正常的**，无法区分异常样本。

下面来分析下为什么会有可能把样本都预测为正常的：

### 为什么有监督可能会把所有样本都预测为正常的

**在异常检测中，我们把异常定义为”Positive“，就和新冠检测阳性一样。**

从损失函数的角度去理解，监督学习的loss函数采用的是条件概率

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/Snipaste_2025-03-07_16-29-17.png)

**同时优化正常样本和异常样本的损失，数据不平衡导致所有都预测为正常**


### 无监督的策略

无监督对正常数据进行密度估计；数学本质是概率密度函数；


![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/Snipaste_2025-03-07_16-33-09.png)


**无监督仅仅优化正常样本的重构误差，模型专注于正常样本的分布，异常自然偏离。**



### 一般提高准确率通常会导致召回率下降，反之亦然

总样本：1000
异常样本(Positive)：10
正常样本(Negative)：990

如果模型将所有样本都预测为正常（Negative）

TP:0 (没有检测到任何异常)
FN:10 （所有异常都被漏检）
FP:0  （没有误报）
TN:990  （所有正常样本都被识别）


召回率就是0，精确率因为分母也为0，没有意义。实际上可能有少数是误报的。





