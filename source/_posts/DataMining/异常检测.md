---
title: 异常检测
date: 2025/03/07
categories:
  - DataMining
tags:
  - 异常检测
mathjax: true
abbrlink: 2ede883b
---



## 无监督训练流程

无监督训练和有监督训练的区别在于没有标签，数据不需要提前标注。之所以采用无监督训练，是因为异常检测领域中异常数据往往是很少的。如果采用有监督训练，那么会优先学习正常数据的分布，就无法识别异常。

采用无监督训练，一种常见的策略是重建。我们这里以设备监控为例，一台设备在100个连续时刻采集了5个传感器的数据，这样的数据为一个样本。一共采集10个这样的数据。输入维度为（10，100，5）

模型的输出是重构后的时序数据，与原始的数据比较后，计算Loss，反向传播更新参数。设定阈值，假设超过阈值的就是异常，就判定哪个时刻，哪个传感器的值是异常的。


## 无监督和自监督的区别

深度学习中，自监督(self-supervised)和无监督(unsupervised)有什么区别？ - Zarathustra的回答 - 知乎
https://www.zhihu.com/question/329202439/answer/2786160932

**自监督学习与无监督学习，这二者就是一样的**

## 评价指标

混淆矩阵是分类任务中评价指标很重要的概念。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/v2-4e0f7a071cd42e3a19e5fc594e35443b_1440w.jpg)

Positive/Negative 表示的预测结果，前面的True/False表示预测的结果是否为真。

- True Positive(真正, TP)：预测正样本正确 
- True Negative(真负 , TN)：预测负样本正确
- False Positive(假正, FP)：预测正样本错误
- False Negative(假负 , FN)：预测负样本错误

### 准确率

预测正确的结果占所有样本的比例

Accuracy = (TP + TN) / (TP + TN + FP +FN)

### 精确率

预测Positive的成功率占多少

Precision = TP / (TP + FP)

衡量模型的预测可靠性。准确率高意味着模型“宁可漏检，也不错检”。

### 召回率

所有正样本中，被正确预测占多少

Recall = TP / (TP + FN)

衡量模型的覆盖能力。召回率高意味着模型“宁可错检，也不漏检”。


## 为什么在异常样本较少时，大多采用无监督而非有监督


### 有监督学习为什么不行

**核心问题：损失函数设计**

有监督依赖**交叉熵损失函数**优化，目的是最大化正确分类的概率（**学习正常和异常的边界**）。当异常样本极少时（如占比1%以下），损失函数会被正常样本主导，导致模型偏向预测所有样本为正常类别。无法学习异常特征。

![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/Snipaste_2025-03-07_16-29-17.png)

模型直接学习“将所有样本预测为正常”的简单策略，准确率可能高达99%，但对异常完全无效。




### 无监督的策略


无监督方法（如自编码器）通过**重构正常数据分布**检测异常，其核心逻辑与有监督完全不同：

无监督对正常数据进行密度估计；数学本质是概率密度函数；
如果任务是重构，那么训练目标就是最小化预测结果和输入的差异。


![](https://cdn.jsdelivr.net/gh/gaofeng-lin/picture_bed/img1/Snipaste_2025-03-07_16-33-09.png)


**无监督仅仅优化正常样本的重构误差，模型专注于正常样本的分布，只要偏离正常分布，异常自然检测到。**

### 传统无监督存在的问题

如果采用基本的MSE作为loss函数，因为正常数据量太大，导致被正常样本主导，可能过拟合。如果正常样本周围出现噪声，那么有可能因为重构误差大而被判定为异常。

还有一种可能是MSE只从”点“的角度评估，忽略了时序的关联性。比如心跳具有周期性，单点值可能是正常的，但是异常房颤表现为周期紊乱，可能无法捕捉周期性异常。

### 一般提高准确率通常会导致召回率下降，反之亦然

总样本：1000
异常样本(Positive)：10
正常样本(Negative)：990

如果模型将所有样本都预测为正常（Negative）

TP:0 (没有检测到任何异常)
FN:10 （所有异常都被漏检）
FP:0  （没有误报）
TN:990  （所有正常样本都被识别）


召回率就是0，精确率因为分母也为0，没有意义。实际上可能有少数是误报的。




## 显示关联建模（Explicit Association Modeling）


**直接定义和量化时间序列内部或不同变量之间的关联关系**来进行异常检测的方法。这类方法的核心是**人为设定或数学化描述变量间的相互作用模式**​（如线性关系、状态转移、图连接等），而非依赖神经网络等黑箱模型隐式学习关联。

典型方法有：向量自回归、状态空间模型、基于图的方法

与隐式关联建模（如深度学习相比），显示关联建模可解释性高、计算成本低。但是不适用非线性关系场景。


尽管显式方法在复杂场景中被神经网络取代，但其思想仍被借鉴：

**​图神经网络（GNN）​：**
结合显式图结构与隐式特征学习，如用Transformer建模时空图（如STGNN）。
**​可解释性AI：**
在神经网络中引入显式关联约束（如稀疏注意力、因果掩码），增强可解释性。
**​混合建模：**
用VAR捕捉线性趋势，用LSTM拟合非线性残差，提升预测鲁棒性。
